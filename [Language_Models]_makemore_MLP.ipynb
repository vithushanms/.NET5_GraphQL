{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vithushanms/.NET5_GraphQL/blob/main/%5BLanguage_Models%5D_makemore_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "jV_VKEpC1SEs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6lGUb1f1WXO",
        "outputId": "0a6a081f-e336-45fb-c967-f9b69b7677e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#if cloud\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataFilePath = '/content/drive/My Drive/Publications/Neural Networks Research/makemore: next char prediction language model/names.txt'\n",
        "words = open(dataFilePath, 'r').read().splitlines() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_gPeNo21azj",
        "outputId": "b2749fbd-1041-492e-b87e-be0f762ea4d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJRK_EOV1_8U",
        "outputId": "296c9e2a-2852-4c54-9d14-e272b57d8d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ],
      "source": [
        "# encode chars in the words to integer\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Bd8760V_ok",
        "outputId": "7245fd09-1ece-43b6-af8d-95103b9731d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "[0] * 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_L5IWrf2M2i",
        "outputId": "145520ba-ce0d-4b04-a06b-5780bef81f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "olivia\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "ava\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "isabella\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "sophia\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n"
          ]
        }
      ],
      "source": [
        "# build the dataset\n",
        "\n",
        "'''\n",
        "build the dataset while having the block_size (the number of chars we are going to input at a time) as 3\n",
        "'''\n",
        "block_size = 3 \n",
        "X, Y = [], []\n",
        "for w in words[:5]:\n",
        "  print(w)\n",
        "  context = [0] * block_size\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "    context = context[1:] + [ix]\n",
        "  \n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X.shape = 32, 3 as the number of inputs are 32 and each have 3 charector input\n",
        "Y.shape = 32, 1 as the number of outcome are 32 and for each respective inputs of 3 charactor there will be one output"
      ],
      "metadata": {
        "id": "qSBgym2lfZEL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shDqtLHNCg9u"
      },
      "source": [
        "As a next step we should encode the dataset X to some sort of format that should be light weight at the same time have the context. \n",
        "\n",
        "If we use the one hot encoding this would work for this particular case as it's only 27 distinct charecter we have in our dataset. but if we take large language models posibily there would be more than a billion distict words makes that diemention to the input set. Therefore we need to scale it down to a smaller diemention without loosing the quality of the prediction. So for that and the following reasons we should scale down the data.\n",
        "\n",
        "*   Sparsity: One-hot encoded vectors are sparse, with only one element being 1 and the rest being 0. This can lead to high memory usage, especially for large vocabularies, as each word requires a vector of the size of the vocabulary.\n",
        "*   Computational complexity: Since one-hot encoded vectors are high-dimensional, matrix multiplications and other operations in the model become computationally expensive. By reducing the dimensionality, you can significantly speed up training and inference.\n",
        "* No semantic information: One-hot encoded vectors don't capture any semantic relationships between words, as they are orthogonal to each other. Word embeddings, on the other hand, are dense vector representations that capture semantic relationships, making it easier for the model to learn and generalize from the data.\n",
        "* Poor generalization: One-hot encoding does not support handling out-of-vocabulary words or handling new words that were not seen during training. Word embeddings can help in this regard by generating embeddings for previously unseen words based on their morphological or contextual similarities to known words.\n",
        "* Difficulty in capturing context: One-hot encoded vectors don't capture context information effectively. Word embeddings, especially when used in combination with more advanced techniques like transformers, can capture long-range dependencies and contextual information, enabling the model to better understand and generate coherent sequences of text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "daGO2xXNCU-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e99fc3-3c35-4729-fab6-8ef30e67db35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6811, 0.2403], grad_fn=<SqueezeBackward3>)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "# we can use the matrix multiplication to scale it down. ex (32,27) * (27,2) = (32,2) \n",
        "#Also this is going to be the first layer / input layer of the MLP\n",
        "C = torch.rand(27,2, requires_grad=True)\n",
        "#example with a one hot encoding of 5\n",
        "five_en = torch.nn.functional.one_hot(torch.tensor(5), num_classes=27).float()\n",
        "(five_en @ C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnPA_5tsCZpC",
        "outputId": "5e00282f-73e4-4ea7-87e5-ed15ac174b13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6811, 0.2403], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "#apperently this is same as what we are going to get by the integer representation itself|\n",
        "C[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiVsULbXDvjg"
      },
      "source": [
        "So we can dierectly use indexing here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjQfNLzSDroh",
        "outputId": "d380e98e-dbac-42d5-b67b-8716ad70c190"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "# we can index the whole data set at one go\n",
        "C[X].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is resulting with 32, 3, 2 because we have 32 lines of inputs and each input has 3 character and each character is encoded to 2 diemention instead of 27"
      ],
      "metadata": {
        "id": "Y4JxNLxrlxF6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "RyHyEN71ElUI"
      },
      "outputs": [],
      "source": [
        "emb = C[X]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But at some point we need to concatinate the 3 character encodings as we need to pass them all together to the inputs to next layer of the model"
      ],
      "metadata": {
        "id": "a-21hKWJm_qR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnoP7FNnFk96",
        "outputId": "cfe10fef-a94d-499c-d0e2-fdab37872b7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "# we can use torch.cat\n",
        "torch.cat([emb[: , 0, :], emb[:, 1, :], emb[:, 2, :]], dim=1).shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use view which is the most efficent way\n",
        "emb.view(32,6).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWKZsFb4noSE",
        "outputId": "e2c859c7-4110-4f90-c8ab-211ad783096d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "view() is used to reshape a tensor without altering its underlying data. It returns a new tensor with the specified dimensions that shares the same data with the original tensor. The primary goal of view() is to change the dimensions of a tensor to match the input or output requirements of neural network layers or other operations.\n",
        "\n",
        "torch.cat() is used to concatenate multiple tensors along a specified dimension. This operation combines the input tensors into a single larger tensor, effectively \"stacking\" them along the chosen axis. The input tensors must have the same shape along all dimensions except for the one being concatenated.\n",
        "\n",
        "However in this spesific scenario the data arrangement is going to the same in both the cases as we are effectivly slicing the input. But view is slightly efficent as it's just a reshape operation performed in the same tensor rather than creating a tensor and copying the data to the new diemension in torch.cat"
      ],
      "metadata": {
        "id": "5RvQKxmmsbLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([emb[: , 0, :], emb[:, 1, :], emb[:, 2, :]], dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Txdy3xC_-aY",
        "outputId": "9bcaa5a6-09a0-4642-d0b0-3e95a76bb309"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1728, 0.5642, 0.1728, 0.5642, 0.1728, 0.5642],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.6811, 0.2403],\n",
              "        [0.1728, 0.5642, 0.6811, 0.2403, 0.9375, 0.1382],\n",
              "        [0.6811, 0.2403, 0.9375, 0.1382, 0.9375, 0.1382],\n",
              "        [0.9375, 0.1382, 0.9375, 0.1382, 0.2328, 0.6608],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.1728, 0.5642],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.7800, 0.8583],\n",
              "        [0.1728, 0.5642, 0.7800, 0.8583, 0.7092, 0.9799],\n",
              "        [0.7800, 0.8583, 0.7092, 0.9799, 0.9501, 0.9993],\n",
              "        [0.7092, 0.9799, 0.9501, 0.9993, 0.9483, 0.6973],\n",
              "        [0.9501, 0.9993, 0.9483, 0.6973, 0.9501, 0.9993],\n",
              "        [0.9483, 0.6973, 0.9501, 0.9993, 0.2328, 0.6608],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.1728, 0.5642],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.2328, 0.6608],\n",
              "        [0.1728, 0.5642, 0.2328, 0.6608, 0.9483, 0.6973],\n",
              "        [0.2328, 0.6608, 0.9483, 0.6973, 0.2328, 0.6608],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.1728, 0.5642],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.9501, 0.9993],\n",
              "        [0.1728, 0.5642, 0.9501, 0.9993, 0.1516, 0.8287],\n",
              "        [0.9501, 0.9993, 0.1516, 0.8287, 0.2328, 0.6608],\n",
              "        [0.1516, 0.8287, 0.2328, 0.6608, 0.7167, 0.4620],\n",
              "        [0.2328, 0.6608, 0.7167, 0.4620, 0.6811, 0.2403],\n",
              "        [0.7167, 0.4620, 0.6811, 0.2403, 0.7092, 0.9799],\n",
              "        [0.6811, 0.2403, 0.7092, 0.9799, 0.7092, 0.9799],\n",
              "        [0.7092, 0.9799, 0.7092, 0.9799, 0.2328, 0.6608],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.1728, 0.5642],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.1516, 0.8287],\n",
              "        [0.1728, 0.5642, 0.1516, 0.8287, 0.7800, 0.8583],\n",
              "        [0.1516, 0.8287, 0.7800, 0.8583, 0.2121, 0.5900],\n",
              "        [0.7800, 0.8583, 0.2121, 0.5900, 0.9257, 0.2552],\n",
              "        [0.2121, 0.5900, 0.9257, 0.2552, 0.9501, 0.9993],\n",
              "        [0.9257, 0.2552, 0.9501, 0.9993, 0.2328, 0.6608]],\n",
              "       grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32,6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTMHA3afqdmI",
        "outputId": "39b512d7-94ba-42f9-c10b-716af85316bf"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1728, 0.5642, 0.1728, 0.5642, 0.1728, 0.5642],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.6811, 0.2403],\n",
              "        [0.1728, 0.5642, 0.6811, 0.2403, 0.9375, 0.1382],\n",
              "        [0.6811, 0.2403, 0.9375, 0.1382, 0.9375, 0.1382],\n",
              "        [0.9375, 0.1382, 0.9375, 0.1382, 0.2328, 0.6608],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.1728, 0.5642],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.7800, 0.8583],\n",
              "        [0.1728, 0.5642, 0.7800, 0.8583, 0.7092, 0.9799],\n",
              "        [0.7800, 0.8583, 0.7092, 0.9799, 0.9501, 0.9993],\n",
              "        [0.7092, 0.9799, 0.9501, 0.9993, 0.9483, 0.6973],\n",
              "        [0.9501, 0.9993, 0.9483, 0.6973, 0.9501, 0.9993],\n",
              "        [0.9483, 0.6973, 0.9501, 0.9993, 0.2328, 0.6608],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.1728, 0.5642],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.2328, 0.6608],\n",
              "        [0.1728, 0.5642, 0.2328, 0.6608, 0.9483, 0.6973],\n",
              "        [0.2328, 0.6608, 0.9483, 0.6973, 0.2328, 0.6608],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.1728, 0.5642],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.9501, 0.9993],\n",
              "        [0.1728, 0.5642, 0.9501, 0.9993, 0.1516, 0.8287],\n",
              "        [0.9501, 0.9993, 0.1516, 0.8287, 0.2328, 0.6608],\n",
              "        [0.1516, 0.8287, 0.2328, 0.6608, 0.7167, 0.4620],\n",
              "        [0.2328, 0.6608, 0.7167, 0.4620, 0.6811, 0.2403],\n",
              "        [0.7167, 0.4620, 0.6811, 0.2403, 0.7092, 0.9799],\n",
              "        [0.6811, 0.2403, 0.7092, 0.9799, 0.7092, 0.9799],\n",
              "        [0.7092, 0.9799, 0.7092, 0.9799, 0.2328, 0.6608],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.1728, 0.5642],\n",
              "        [0.1728, 0.5642, 0.1728, 0.5642, 0.1516, 0.8287],\n",
              "        [0.1728, 0.5642, 0.1516, 0.8287, 0.7800, 0.8583],\n",
              "        [0.1516, 0.8287, 0.7800, 0.8583, 0.2121, 0.5900],\n",
              "        [0.7800, 0.8583, 0.2121, 0.5900, 0.9257, 0.2552],\n",
              "        [0.2121, 0.5900, 0.9257, 0.2552, 0.9501, 0.9993],\n",
              "        [0.9257, 0.2552, 0.9501, 0.9993, 0.2328, 0.6608]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Multilayer Perceptron (MLP) is a type of artificial neural network that can be used for language modeling tasks. The following are some of the hyperparameters that can be adjusted in an MLP for language modeling:\n",
        "\n",
        "1. Architecture: The number of hidden layers and the number of neurons in each layer can be adjusted. Increasing the number of hidden layers and neurons can increase the capacity of the model, but also increase the risk of overfitting.\n",
        "\n",
        "2. Activation Function: The activation function used in each layer can be adjusted. Common choices include ReLU, sigmoid, and tanh.\n",
        "\n",
        "3. Learning Rate: The learning rate determines the step size used to update the model's parameters during training. A too-high learning rate can cause the model to converge slowly or not at all, while a too-low learning rate can cause the model to converge too slowly.\n",
        "\n",
        "4. Momentum: Momentum is a hyperparameter used in gradient descent optimization algorithms to speed up convergence. It adds a fraction of the update vector of the past time step to the current update vector.\n",
        "\n",
        "5. Regularization: Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function. Common choices include L1 and L2 regularization, and dropout.\n",
        "\n",
        "6. Batch Size: The batch size determines the number of samples used in one iteration of training. Larger batch sizes can lead to faster training, but may also require more memory.\n",
        "\n",
        "7. Epochs: The number of training epochs determines how many times the model will see the entire training dataset. More epochs can lead to better model performance, but also increase the risk of overfitting.\n",
        "\n",
        "These are some of the most common hyperparameters that can be adjusted in an MLP for language modeling. The optimal values for these hyperparameters depend on the specific task and dataset, and often require experimentation to determine.\n",
        "\n",
        "These hyperparameter can be optimized mostly by the trial and errors during the training "
      ],
      "metadata": {
        "id": "TBIVk54LusbQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "IxeWKGiNHcr1"
      },
      "outputs": [],
      "source": [
        "#create hidden layer. having 100 neurons initially and adding tanh as an activation function\n",
        "W1 = torch.randn((6,100), requires_grad=True)\n",
        "b = torch.randn(100, requires_grad=True)\n",
        "out_1 = emb.view(32,6) @ W1 + b\n",
        "out_h = torch.tanh(out_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsAA5gpdJdvZ",
        "outputId": "5e28c0fb-aefb-4a5f-e656-2d66e9d71fb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "out_h.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "ieM1oPF9Jftl"
      },
      "outputs": [],
      "source": [
        "#create final layer. we are using the softmax for activation function as the expecation to get a probability of each character in 27\n",
        "W2 = torch.randn((100,27) , requires_grad=True)\n",
        "b2 = torch.randn(27, requires_grad=True)\n",
        "logits = out_h @ W2 + b2  \n",
        "#perform softmax\n",
        "counts = torch.exp(logits)\n",
        "counts.shape\n",
        "prob = counts / counts.sum(1, keepdim=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emphasize differences: Exponentiating logits makes the differences between large and small logits more pronounced, causing the softmax function to produce more distinct probabilities. This property is helpful in tasks like classification, where you want the model to be more confident in its predictions.\n",
        "\n",
        "Non-negative probabilities: Exponentiating logits ensures that the resulting probabilities are non-negative, as the exponential function e^x is always positive for any x. This is important because probabilities should always be non-negative by definition.\n",
        "\n",
        "Normalization: After exponentiating logits, they are normalized by dividing each exponentiated logit by the sum of all exponentiated logits. This normalization step ensures that the resulting probabilities sum up to 1, which is a requirement for a valid probability distribution."
      ],
      "metadata": {
        "id": "7Sl3J-2Sw0vk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gavMCZ0vKZFL",
        "outputId": "abbbe655-217d-40c9-d5fd-71778d1c492e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "prob.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mE10QkTLLeV",
        "outputId": "5eabba87-0241-49a3-fe23-7c3bc104c04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- y actual : e --> 5 \n",
            "---- predicted probabilities :  tensor([7.6692e-05, 4.2762e-02, 1.6194e-04, 7.5072e-08, 4.6627e-01, 7.9406e-05,\n",
            "        3.2504e-02, 5.2626e-09, 2.7080e-01, 1.6396e-07, 1.3619e-05, 7.2042e-04,\n",
            "        1.0136e-04, 1.1874e-07, 4.1913e-07, 1.8226e-01, 1.3920e-06, 3.2976e-06,\n",
            "        4.4810e-06, 4.7982e-09, 3.4682e-05, 6.7459e-08, 5.8284e-08, 2.1400e-05,\n",
            "        5.1962e-06, 3.9390e-12, 4.1876e-03], grad_fn=<SelectBackward0>)\n",
            "---- predicted probability of e 7.940554496599361e-05 \n",
            "---- y actual : m --> 13 \n",
            "---- predicted probabilities :  tensor([2.8837e-02, 2.0960e-01, 3.2999e-04, 2.3308e-07, 6.0434e-01, 2.7638e-06,\n",
            "        3.3091e-04, 6.0075e-09, 6.5271e-03, 1.8370e-07, 4.5106e-06, 6.1224e-03,\n",
            "        1.2553e-04, 9.0463e-10, 5.3147e-07, 1.4123e-01, 6.6871e-09, 4.2949e-07,\n",
            "        3.7239e-06, 1.0615e-10, 1.2857e-04, 1.5257e-10, 1.5976e-06, 5.8359e-05,\n",
            "        2.5933e-07, 9.5356e-12, 2.3507e-03], grad_fn=<SelectBackward0>)\n",
            "---- predicted probability of m 9.046257076761322e-10 \n"
          ]
        }
      ],
      "source": [
        "for i in range(len(Y[:2])):\n",
        "  iy = Y[i].item()\n",
        "  print(f'---- y actual : {itos[iy]} --> {iy} ')\n",
        "  print('---- predicted probabilities : ', prob[i])\n",
        "  print(f'---- predicted probability of {itos[iy]} {prob[i][iy]} ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75aK1OjNQ5wH",
        "outputId": "084a304c-8743-45b0-f540-c1d487f5c1d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.9406e-05, 9.0463e-10, 2.6306e-09, 2.5379e-02, 1.0564e-07, 1.8226e-01,\n",
              "        4.3930e-05, 6.3609e-08, 7.3472e-08, 1.0054e-08, 1.9696e-02, 4.1512e-03,\n",
              "        4.2762e-02, 1.5871e-06, 2.1677e-01, 5.4982e-04, 1.6396e-07, 3.3729e-11,\n",
              "        9.5087e-01, 1.7362e-04, 2.6468e-07, 1.0213e-05, 4.0064e-05, 1.2164e-02,\n",
              "        1.7735e-04, 4.7982e-09, 6.1455e-03, 1.6214e-06, 4.8349e-05, 2.3233e-09,\n",
              "        4.5359e-03, 8.3696e-07], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "#get the probability of y act from all the respective 32 input feature set \n",
        "prob[torch.arange(32), Y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "Rj1sVNLFLzQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4cbe745-d7ae-4364-f8f5-4def9ea76781"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11.0280, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "#calculate the log likelyhood which is the loss\n",
        "loss = nll = -prob[torch.arange(32),Y].log().mean() \n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dik3Vt87Qzpy",
        "outputId": "bc58f695-7c28-48b7-e15e-1411950ee497"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "#parameter of the model\n",
        "parameters = [C, W1, b, W2, b2]\n",
        "sum(p.nelement() for p in parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross_entropy is a built in feature within the pytorch that calculates the negative log likelyhood againt the Y actual after performing the softmax from the given logits. and as it's inbuilt, this is much more effiecent to use"
      ],
      "metadata": {
        "id": "PMxrPba9yW1B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k__5YzcLUw0v",
        "outputId": "37e1acf9-a395-467a-a529-f9c27fdcbfc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11.0280, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "#there is an internal impl in pytourch which calculates the loss directly\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfT-bmNiciNJ",
        "outputId": "71032322-5fff-40d4-9fb2-308b33417cdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.6876, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "#backpropogate and tune the model\n",
        "for i in range(10):\n",
        "  #forward\n",
        "  emb = C[X]\n",
        "  out_1 = emb.view(-1,6) @ W1 + b\n",
        "  out_h = torch.tanh(out_1)\n",
        "  logits = out_h @ W2 + b2  \n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "  #backward\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "  #update\n",
        "  for p in parameters:\n",
        "    p.data += -0.5 * p.grad\n",
        "\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far we have tried with only first five names from the data set. so let's try the same approach with the whole data set"
      ],
      "metadata": {
        "id": "O6mdiMTcB3G3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "L049PXX9dXbj"
      },
      "outputs": [],
      "source": [
        "X, Y = [], []\n",
        "\n",
        "for name in words:\n",
        "  context = [0] * 3\n",
        "  for ch in name + '.':\n",
        "    ix = stoi[ch]\n",
        "    Y.append(ix)\n",
        "    X.append(context)\n",
        "    context = context[1:] + [ix]\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do we use tensors instead of normal array\n",
        "\n",
        "1. Efficient computation on GPUs: torch.Tensor has built-in support for GPU acceleration, which makes it much faster than standard multidimensional arrays when performing computationally intensive operations. This is especially important in machine learning, where large amounts of data need to be processed quickly.\n",
        "\n",
        "2. Automatic differentiation: torch.Tensor supports automatic differentiation, which is a key feature for training neural networks using techniques like backpropagation. Automatic differentiation allows you to easily calculate gradients of complex functions, which is essential for optimizing model parameters.\n",
        "\n",
        "3. Extensive library support: torch.Tensor is part of the PyTorch library, which has extensive support for machine learning and scientific computing. PyTorch includes many useful tools for building and training neural networks, such as built-in loss functions, optimizers, and activation functions.\n",
        "\n",
        "4. Flexible data types: torch.Tensor supports a wide range of data types, including floating-point numbers, integers, and Boolean values. This flexibility makes it easy to work with different types of data, which is important in many scientific and engineering applications."
      ],
      "metadata": {
        "id": "klrJOApMIyQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27,2),requires_grad=True)\n",
        "W1 = torch.randn((6,100), requires_grad=True)\n",
        "b1 = torch.randn(100, requires_grad=True)\n",
        "W2 = torch.randn((100, 27), requires_grad=True)\n",
        "b2 = torch.randn(27, requires_grad=True)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "l72DE7aAJLS-"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "out_h = (emb.view(-1, 6) @ W1 + b1).tanh()\n",
        "logits = out_h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0BMqdkwNn_A",
        "outputId": "ac17bda6-5a84-44a9-9bd9-d93e1f6a9788"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.0425, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  #forward pass\n",
        "  emb = C[X]\n",
        "  logits = ((emb.view(-1,6) @ W1 + b1).tanh()) @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "\n",
        "  #backward\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  #tune the parameters\n",
        "  for p in parameters:\n",
        "    p.data += -0.1 * p.grad"
      ],
      "metadata": {
        "id": "MI5VgEF-TekU"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPjsUmCSU6Fn",
        "outputId": "f5861fd8-c58c-441c-c3f6-cac673794767"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.699881553649902"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing a good learning rate is a critical step when training a Multilayer Perceptron (MLP) using backpropagation. Here are some methods to determine a better learning rate:\n",
        "--\n",
        "\n",
        "1. Grid Search: Grid search is a simple but effective way to find a good learning rate. In this method, you specify a range of learning rates and train the MLP with each learning rate in the range. You can then evaluate the performance of the model for each learning rate and choose the one that performs best.\n",
        "\n",
        "2. Learning Rate Range Test: The learning rate range test is a more automated way to determine a good learning rate. In this method, you start with a very small learning rate and increase it exponentially while training the model. You can then plot the loss as a function of learning rate and choose the value at which the loss starts to decrease the most rapidly. This method can help you find a good learning rate quickly and without much manual effort.\n",
        "\n",
        "3. Adaptive Learning Rates: Adaptive learning rate methods, such as Adam and Adagrad, adjust the learning rate automatically during training based on the gradients of the loss function. These methods can be more effective than manually tuning the learning rate, as they can adapt to the specific characteristics of the problem being solved.\n",
        "\n",
        "4. Learning Rate Schedules: Learning rate schedules adjust the learning rate over time, typically reducing it as training progresses. Commonly used learning rate schedules include step decay, where the learning rate is reduced by a fixed factor after a certain number of epochs, and exponential decay, where the learning rate is reduced exponentially over time. These methods can help prevent the learning rate from becoming too large during later stages of training, when the gradients are smaller.\n",
        "\n",
        "Overall, choosing a good learning rate can be a bit of an art, and it may require some experimentation to find the best approach for a particular problem. However, these methods provide a good starting point for finding a suitable learning rate for an MLP with backpropagation.\n",
        "\n",
        "on the learning rate range why are we having to increase  exponentially instead of evenly  \n",
        "--\n",
        "When using the learning rate range test to determine a good learning rate, it is often beneficial to increase the learning rate exponentially instead of evenly. The reason for this is that the effect of the learning rate on the loss function can be highly nonlinear, and it can be difficult to identify the optimal learning rate by sampling uniformly over a range of learning rates.\n",
        "\n",
        "Increasing the learning rate exponentially allows us to cover a wider range of learning rates more quickly, while still being able to identify the learning rates that have the greatest impact on the loss function. By starting with a small learning rate and increasing it exponentially, we can quickly move through the range of learning rates and identify the point at which the loss starts to decrease rapidly. This point typically corresponds to a learning rate that is just large enough to make significant progress in reducing the loss, without causing the loss to become unstable.\n",
        "\n",
        "In addition, increasing the learning rate exponentially helps to avoid getting stuck in local minima by allowing the model to explore a wider range of learning rates. By gradually increasing the learning rate, the model can learn more quickly and avoid getting stuck in a suboptimal solution. This can be especially important in deep learning, where the loss function can have many local minima.\n",
        "\n",
        "Overall, using an exponential increase in the learning rate can help to identify a good learning rate more efficiently and effectively than sampling uniformly over a range of learning rates.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xQmjYYpPXDkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# between 0.001 and 1 is a better limit as it seem to be exploding anything beyound this\n",
        "lre = torch.linspace(-3, 1 , 1000)\n",
        "lrs = 10 ** lre\n",
        "lrs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQO-FdxE65q_",
        "outputId": "1a85a014-cdb5-41d4-e988-289ea973ebba"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e-03, 1.0093e-03, 1.0186e-03, 1.0280e-03, 1.0376e-03, 1.0472e-03,\n",
              "        1.0569e-03, 1.0667e-03, 1.0765e-03, 1.0865e-03, 1.0966e-03, 1.1067e-03,\n",
              "        1.1170e-03, 1.1273e-03, 1.1378e-03, 1.1483e-03, 1.1589e-03, 1.1697e-03,\n",
              "        1.1805e-03, 1.1915e-03, 1.2025e-03, 1.2136e-03, 1.2249e-03, 1.2362e-03,\n",
              "        1.2477e-03, 1.2592e-03, 1.2709e-03, 1.2826e-03, 1.2945e-03, 1.3065e-03,\n",
              "        1.3186e-03, 1.3308e-03, 1.3432e-03, 1.3556e-03, 1.3682e-03, 1.3808e-03,\n",
              "        1.3936e-03, 1.4065e-03, 1.4196e-03, 1.4327e-03, 1.4460e-03, 1.4594e-03,\n",
              "        1.4729e-03, 1.4865e-03, 1.5003e-03, 1.5142e-03, 1.5282e-03, 1.5424e-03,\n",
              "        1.5567e-03, 1.5711e-03, 1.5856e-03, 1.6003e-03, 1.6151e-03, 1.6301e-03,\n",
              "        1.6452e-03, 1.6604e-03, 1.6758e-03, 1.6913e-03, 1.7070e-03, 1.7228e-03,\n",
              "        1.7388e-03, 1.7549e-03, 1.7711e-03, 1.7875e-03, 1.8041e-03, 1.8208e-03,\n",
              "        1.8377e-03, 1.8547e-03, 1.8719e-03, 1.8892e-03, 1.9067e-03, 1.9244e-03,\n",
              "        1.9422e-03, 1.9602e-03, 1.9783e-03, 1.9966e-03, 2.0151e-03, 2.0338e-03,\n",
              "        2.0526e-03, 2.0717e-03, 2.0908e-03, 2.1102e-03, 2.1297e-03, 2.1495e-03,\n",
              "        2.1694e-03, 2.1895e-03, 2.2098e-03, 2.2302e-03, 2.2509e-03, 2.2717e-03,\n",
              "        2.2928e-03, 2.3140e-03, 2.3354e-03, 2.3571e-03, 2.3789e-03, 2.4009e-03,\n",
              "        2.4232e-03, 2.4456e-03, 2.4683e-03, 2.4911e-03, 2.5142e-03, 2.5375e-03,\n",
              "        2.5610e-03, 2.5847e-03, 2.6087e-03, 2.6328e-03, 2.6572e-03, 2.6818e-03,\n",
              "        2.7067e-03, 2.7317e-03, 2.7570e-03, 2.7826e-03, 2.8083e-03, 2.8343e-03,\n",
              "        2.8606e-03, 2.8871e-03, 2.9138e-03, 2.9408e-03, 2.9681e-03, 2.9955e-03,\n",
              "        3.0233e-03, 3.0513e-03, 3.0796e-03, 3.1081e-03, 3.1369e-03, 3.1659e-03,\n",
              "        3.1952e-03, 3.2248e-03, 3.2547e-03, 3.2849e-03, 3.3153e-03, 3.3460e-03,\n",
              "        3.3770e-03, 3.4083e-03, 3.4398e-03, 3.4717e-03, 3.5038e-03, 3.5363e-03,\n",
              "        3.5690e-03, 3.6021e-03, 3.6355e-03, 3.6691e-03, 3.7031e-03, 3.7374e-03,\n",
              "        3.7720e-03, 3.8070e-03, 3.8422e-03, 3.8778e-03, 3.9137e-03, 3.9500e-03,\n",
              "        3.9866e-03, 4.0235e-03, 4.0608e-03, 4.0984e-03, 4.1363e-03, 4.1747e-03,\n",
              "        4.2133e-03, 4.2523e-03, 4.2917e-03, 4.3315e-03, 4.3716e-03, 4.4121e-03,\n",
              "        4.4530e-03, 4.4942e-03, 4.5358e-03, 4.5778e-03, 4.6202e-03, 4.6630e-03,\n",
              "        4.7062e-03, 4.7498e-03, 4.7938e-03, 4.8382e-03, 4.8830e-03, 4.9283e-03,\n",
              "        4.9739e-03, 5.0200e-03, 5.0665e-03, 5.1134e-03, 5.1607e-03, 5.2085e-03,\n",
              "        5.2568e-03, 5.3055e-03, 5.3546e-03, 5.4042e-03, 5.4543e-03, 5.5048e-03,\n",
              "        5.5558e-03, 5.6072e-03, 5.6592e-03, 5.7116e-03, 5.7645e-03, 5.8179e-03,\n",
              "        5.8718e-03, 5.9262e-03, 5.9810e-03, 6.0364e-03, 6.0923e-03, 6.1488e-03,\n",
              "        6.2057e-03, 6.2632e-03, 6.3212e-03, 6.3798e-03, 6.4389e-03, 6.4985e-03,\n",
              "        6.5587e-03, 6.6194e-03, 6.6807e-03, 6.7426e-03, 6.8051e-03, 6.8681e-03,\n",
              "        6.9317e-03, 6.9959e-03, 7.0607e-03, 7.1261e-03, 7.1921e-03, 7.2587e-03,\n",
              "        7.3260e-03, 7.3938e-03, 7.4623e-03, 7.5314e-03, 7.6012e-03, 7.6716e-03,\n",
              "        7.7426e-03, 7.8143e-03, 7.8867e-03, 7.9598e-03, 8.0335e-03, 8.1079e-03,\n",
              "        8.1830e-03, 8.2588e-03, 8.3353e-03, 8.4125e-03, 8.4904e-03, 8.5691e-03,\n",
              "        8.6484e-03, 8.7285e-03, 8.8094e-03, 8.8910e-03, 8.9733e-03, 9.0564e-03,\n",
              "        9.1403e-03, 9.2250e-03, 9.3104e-03, 9.3966e-03, 9.4837e-03, 9.5715e-03,\n",
              "        9.6602e-03, 9.7496e-03, 9.8400e-03, 9.9311e-03, 1.0023e-02, 1.0116e-02,\n",
              "        1.0210e-02, 1.0304e-02, 1.0400e-02, 1.0496e-02, 1.0593e-02, 1.0691e-02,\n",
              "        1.0790e-02, 1.0890e-02, 1.0991e-02, 1.1093e-02, 1.1196e-02, 1.1299e-02,\n",
              "        1.1404e-02, 1.1510e-02, 1.1616e-02, 1.1724e-02, 1.1832e-02, 1.1942e-02,\n",
              "        1.2053e-02, 1.2164e-02, 1.2277e-02, 1.2391e-02, 1.2505e-02, 1.2621e-02,\n",
              "        1.2738e-02, 1.2856e-02, 1.2975e-02, 1.3095e-02, 1.3217e-02, 1.3339e-02,\n",
              "        1.3463e-02, 1.3587e-02, 1.3713e-02, 1.3840e-02, 1.3968e-02, 1.4098e-02,\n",
              "        1.4228e-02, 1.4360e-02, 1.4493e-02, 1.4627e-02, 1.4763e-02, 1.4900e-02,\n",
              "        1.5038e-02, 1.5177e-02, 1.5317e-02, 1.5459e-02, 1.5602e-02, 1.5747e-02,\n",
              "        1.5893e-02, 1.6040e-02, 1.6189e-02, 1.6339e-02, 1.6490e-02, 1.6643e-02,\n",
              "        1.6797e-02, 1.6952e-02, 1.7109e-02, 1.7268e-02, 1.7428e-02, 1.7589e-02,\n",
              "        1.7752e-02, 1.7917e-02, 1.8082e-02, 1.8250e-02, 1.8419e-02, 1.8590e-02,\n",
              "        1.8762e-02, 1.8936e-02, 1.9111e-02, 1.9288e-02, 1.9467e-02, 1.9647e-02,\n",
              "        1.9829e-02, 2.0012e-02, 2.0198e-02, 2.0385e-02, 2.0574e-02, 2.0764e-02,\n",
              "        2.0957e-02, 2.1151e-02, 2.1347e-02, 2.1544e-02, 2.1744e-02, 2.1945e-02,\n",
              "        2.2149e-02, 2.2354e-02, 2.2561e-02, 2.2770e-02, 2.2981e-02, 2.3193e-02,\n",
              "        2.3408e-02, 2.3625e-02, 2.3844e-02, 2.4065e-02, 2.4288e-02, 2.4513e-02,\n",
              "        2.4740e-02, 2.4969e-02, 2.5200e-02, 2.5433e-02, 2.5669e-02, 2.5907e-02,\n",
              "        2.6147e-02, 2.6389e-02, 2.6633e-02, 2.6880e-02, 2.7129e-02, 2.7380e-02,\n",
              "        2.7634e-02, 2.7890e-02, 2.8148e-02, 2.8409e-02, 2.8672e-02, 2.8938e-02,\n",
              "        2.9206e-02, 2.9476e-02, 2.9749e-02, 3.0025e-02, 3.0303e-02, 3.0583e-02,\n",
              "        3.0867e-02, 3.1153e-02, 3.1441e-02, 3.1732e-02, 3.2026e-02, 3.2323e-02,\n",
              "        3.2622e-02, 3.2924e-02, 3.3229e-02, 3.3537e-02, 3.3848e-02, 3.4161e-02,\n",
              "        3.4478e-02, 3.4797e-02, 3.5119e-02, 3.5445e-02, 3.5773e-02, 3.6104e-02,\n",
              "        3.6439e-02, 3.6776e-02, 3.7117e-02, 3.7461e-02, 3.7807e-02, 3.8158e-02,\n",
              "        3.8511e-02, 3.8868e-02, 3.9228e-02, 3.9591e-02, 3.9958e-02, 4.0328e-02,\n",
              "        4.0701e-02, 4.1078e-02, 4.1459e-02, 4.1843e-02, 4.2230e-02, 4.2622e-02,\n",
              "        4.3016e-02, 4.3415e-02, 4.3817e-02, 4.4223e-02, 4.4632e-02, 4.5046e-02,\n",
              "        4.5463e-02, 4.5884e-02, 4.6309e-02, 4.6738e-02, 4.7171e-02, 4.7608e-02,\n",
              "        4.8049e-02, 4.8494e-02, 4.8943e-02, 4.9396e-02, 4.9854e-02, 5.0315e-02,\n",
              "        5.0782e-02, 5.1252e-02, 5.1727e-02, 5.2206e-02, 5.2689e-02, 5.3177e-02,\n",
              "        5.3670e-02, 5.4167e-02, 5.4669e-02, 5.5175e-02, 5.5686e-02, 5.6202e-02,\n",
              "        5.6722e-02, 5.7248e-02, 5.7778e-02, 5.8313e-02, 5.8853e-02, 5.9398e-02,\n",
              "        5.9948e-02, 6.0504e-02, 6.1064e-02, 6.1630e-02, 6.2200e-02, 6.2777e-02,\n",
              "        6.3358e-02, 6.3945e-02, 6.4537e-02, 6.5135e-02, 6.5738e-02, 6.6347e-02,\n",
              "        6.6962e-02, 6.7582e-02, 6.8208e-02, 6.8840e-02, 6.9477e-02, 7.0121e-02,\n",
              "        7.0770e-02, 7.1426e-02, 7.2087e-02, 7.2755e-02, 7.3429e-02, 7.4109e-02,\n",
              "        7.4795e-02, 7.5488e-02, 7.6187e-02, 7.6893e-02, 7.7605e-02, 7.8324e-02,\n",
              "        7.9049e-02, 7.9781e-02, 8.0520e-02, 8.1266e-02, 8.2019e-02, 8.2779e-02,\n",
              "        8.3545e-02, 8.4319e-02, 8.5100e-02, 8.5888e-02, 8.6684e-02, 8.7487e-02,\n",
              "        8.8297e-02, 8.9115e-02, 8.9940e-02, 9.0773e-02, 9.1614e-02, 9.2463e-02,\n",
              "        9.3319e-02, 9.4183e-02, 9.5056e-02, 9.5936e-02, 9.6825e-02, 9.7721e-02,\n",
              "        9.8627e-02, 9.9540e-02, 1.0046e-01, 1.0139e-01, 1.0233e-01, 1.0328e-01,\n",
              "        1.0424e-01, 1.0520e-01, 1.0618e-01, 1.0716e-01, 1.0815e-01, 1.0915e-01,\n",
              "        1.1016e-01, 1.1118e-01, 1.1221e-01, 1.1325e-01, 1.1430e-01, 1.1536e-01,\n",
              "        1.1643e-01, 1.1751e-01, 1.1860e-01, 1.1970e-01, 1.2080e-01, 1.2192e-01,\n",
              "        1.2305e-01, 1.2419e-01, 1.2534e-01, 1.2650e-01, 1.2768e-01, 1.2886e-01,\n",
              "        1.3005e-01, 1.3126e-01, 1.3247e-01, 1.3370e-01, 1.3494e-01, 1.3619e-01,\n",
              "        1.3745e-01, 1.3872e-01, 1.4001e-01, 1.4130e-01, 1.4261e-01, 1.4393e-01,\n",
              "        1.4527e-01, 1.4661e-01, 1.4797e-01, 1.4934e-01, 1.5072e-01, 1.5212e-01,\n",
              "        1.5353e-01, 1.5495e-01, 1.5638e-01, 1.5783e-01, 1.5930e-01, 1.6077e-01,\n",
              "        1.6226e-01, 1.6376e-01, 1.6528e-01, 1.6681e-01, 1.6836e-01, 1.6991e-01,\n",
              "        1.7149e-01, 1.7308e-01, 1.7468e-01, 1.7630e-01, 1.7793e-01, 1.7958e-01,\n",
              "        1.8124e-01, 1.8292e-01, 1.8461e-01, 1.8632e-01, 1.8805e-01, 1.8979e-01,\n",
              "        1.9155e-01, 1.9332e-01, 1.9511e-01, 1.9692e-01, 1.9875e-01, 2.0059e-01,\n",
              "        2.0244e-01, 2.0432e-01, 2.0621e-01, 2.0812e-01, 2.1005e-01, 2.1200e-01,\n",
              "        2.1396e-01, 2.1594e-01, 2.1794e-01, 2.1996e-01, 2.2200e-01, 2.2405e-01,\n",
              "        2.2613e-01, 2.2822e-01, 2.3034e-01, 2.3247e-01, 2.3462e-01, 2.3680e-01,\n",
              "        2.3899e-01, 2.4120e-01, 2.4344e-01, 2.4569e-01, 2.4797e-01, 2.5026e-01,\n",
              "        2.5258e-01, 2.5492e-01, 2.5728e-01, 2.5967e-01, 2.6207e-01, 2.6450e-01,\n",
              "        2.6695e-01, 2.6942e-01, 2.7192e-01, 2.7443e-01, 2.7698e-01, 2.7954e-01,\n",
              "        2.8213e-01, 2.8474e-01, 2.8738e-01, 2.9004e-01, 2.9273e-01, 2.9544e-01,\n",
              "        2.9818e-01, 3.0094e-01, 3.0373e-01, 3.0654e-01, 3.0938e-01, 3.1224e-01,\n",
              "        3.1514e-01, 3.1806e-01, 3.2100e-01, 3.2397e-01, 3.2697e-01, 3.3000e-01,\n",
              "        3.3306e-01, 3.3614e-01, 3.3926e-01, 3.4240e-01, 3.4557e-01, 3.4877e-01,\n",
              "        3.5200e-01, 3.5526e-01, 3.5855e-01, 3.6187e-01, 3.6523e-01, 3.6861e-01,\n",
              "        3.7202e-01, 3.7547e-01, 3.7895e-01, 3.8246e-01, 3.8600e-01, 3.8957e-01,\n",
              "        3.9318e-01, 3.9682e-01, 4.0050e-01, 4.0421e-01, 4.0795e-01, 4.1173e-01,\n",
              "        4.1555e-01, 4.1939e-01, 4.2328e-01, 4.2720e-01, 4.3116e-01, 4.3515e-01,\n",
              "        4.3918e-01, 4.4325e-01, 4.4735e-01, 4.5150e-01, 4.5568e-01, 4.5990e-01,\n",
              "        4.6416e-01, 4.6846e-01, 4.7280e-01, 4.7718e-01, 4.8160e-01, 4.8606e-01,\n",
              "        4.9056e-01, 4.9510e-01, 4.9969e-01, 5.0432e-01, 5.0899e-01, 5.1370e-01,\n",
              "        5.1846e-01, 5.2326e-01, 5.2811e-01, 5.3300e-01, 5.3794e-01, 5.4292e-01,\n",
              "        5.4795e-01, 5.5302e-01, 5.5814e-01, 5.6331e-01, 5.6853e-01, 5.7380e-01,\n",
              "        5.7911e-01, 5.8448e-01, 5.8989e-01, 5.9535e-01, 6.0087e-01, 6.0643e-01,\n",
              "        6.1205e-01, 6.1772e-01, 6.2344e-01, 6.2921e-01, 6.3504e-01, 6.4092e-01,\n",
              "        6.4686e-01, 6.5285e-01, 6.5890e-01, 6.6500e-01, 6.7116e-01, 6.7738e-01,\n",
              "        6.8365e-01, 6.8998e-01, 6.9637e-01, 7.0282e-01, 7.0933e-01, 7.1590e-01,\n",
              "        7.2253e-01, 7.2923e-01, 7.3598e-01, 7.4280e-01, 7.4968e-01, 7.5662e-01,\n",
              "        7.6363e-01, 7.7070e-01, 7.7784e-01, 7.8505e-01, 7.9232e-01, 7.9966e-01,\n",
              "        8.0706e-01, 8.1454e-01, 8.2208e-01, 8.2970e-01, 8.3738e-01, 8.4514e-01,\n",
              "        8.5296e-01, 8.6086e-01, 8.6884e-01, 8.7689e-01, 8.8501e-01, 8.9320e-01,\n",
              "        9.0148e-01, 9.0983e-01, 9.1825e-01, 9.2676e-01, 9.3534e-01, 9.4401e-01,\n",
              "        9.5275e-01, 9.6157e-01, 9.7048e-01, 9.7947e-01, 9.8854e-01, 9.9770e-01,\n",
              "        1.0069e+00, 1.0163e+00, 1.0257e+00, 1.0352e+00, 1.0448e+00, 1.0544e+00,\n",
              "        1.0642e+00, 1.0741e+00, 1.0840e+00, 1.0941e+00, 1.1042e+00, 1.1144e+00,\n",
              "        1.1247e+00, 1.1352e+00, 1.1457e+00, 1.1563e+00, 1.1670e+00, 1.1778e+00,\n",
              "        1.1887e+00, 1.1997e+00, 1.2108e+00, 1.2220e+00, 1.2334e+00, 1.2448e+00,\n",
              "        1.2563e+00, 1.2680e+00, 1.2797e+00, 1.2915e+00, 1.3035e+00, 1.3156e+00,\n",
              "        1.3278e+00, 1.3401e+00, 1.3525e+00, 1.3650e+00, 1.3777e+00, 1.3904e+00,\n",
              "        1.4033e+00, 1.4163e+00, 1.4294e+00, 1.4426e+00, 1.4560e+00, 1.4695e+00,\n",
              "        1.4831e+00, 1.4968e+00, 1.5107e+00, 1.5247e+00, 1.5388e+00, 1.5531e+00,\n",
              "        1.5675e+00, 1.5820e+00, 1.5966e+00, 1.6114e+00, 1.6263e+00, 1.6414e+00,\n",
              "        1.6566e+00, 1.6719e+00, 1.6874e+00, 1.7031e+00, 1.7188e+00, 1.7348e+00,\n",
              "        1.7508e+00, 1.7670e+00, 1.7834e+00, 1.7999e+00, 1.8166e+00, 1.8334e+00,\n",
              "        1.8504e+00, 1.8675e+00, 1.8848e+00, 1.9023e+00, 1.9199e+00, 1.9377e+00,\n",
              "        1.9557e+00, 1.9738e+00, 1.9920e+00, 2.0105e+00, 2.0291e+00, 2.0479e+00,\n",
              "        2.0669e+00, 2.0860e+00, 2.1053e+00, 2.1248e+00, 2.1445e+00, 2.1644e+00,\n",
              "        2.1844e+00, 2.2047e+00, 2.2251e+00, 2.2457e+00, 2.2665e+00, 2.2875e+00,\n",
              "        2.3087e+00, 2.3301e+00, 2.3516e+00, 2.3734e+00, 2.3954e+00, 2.4176e+00,\n",
              "        2.4400e+00, 2.4626e+00, 2.4854e+00, 2.5084e+00, 2.5316e+00, 2.5551e+00,\n",
              "        2.5788e+00, 2.6026e+00, 2.6268e+00, 2.6511e+00, 2.6756e+00, 2.7004e+00,\n",
              "        2.7254e+00, 2.7507e+00, 2.7762e+00, 2.8019e+00, 2.8278e+00, 2.8540e+00,\n",
              "        2.8804e+00, 2.9071e+00, 2.9340e+00, 2.9612e+00, 2.9887e+00, 3.0163e+00,\n",
              "        3.0443e+00, 3.0725e+00, 3.1009e+00, 3.1296e+00, 3.1586e+00, 3.1879e+00,\n",
              "        3.2174e+00, 3.2472e+00, 3.2773e+00, 3.3076e+00, 3.3383e+00, 3.3692e+00,\n",
              "        3.4004e+00, 3.4319e+00, 3.4637e+00, 3.4958e+00, 3.5282e+00, 3.5608e+00,\n",
              "        3.5938e+00, 3.6271e+00, 3.6607e+00, 3.6946e+00, 3.7288e+00, 3.7634e+00,\n",
              "        3.7982e+00, 3.8334e+00, 3.8689e+00, 3.9047e+00, 3.9409e+00, 3.9774e+00,\n",
              "        4.0142e+00, 4.0514e+00, 4.0889e+00, 4.1268e+00, 4.1650e+00, 4.2036e+00,\n",
              "        4.2426e+00, 4.2819e+00, 4.3215e+00, 4.3615e+00, 4.4019e+00, 4.4427e+00,\n",
              "        4.4839e+00, 4.5254e+00, 4.5673e+00, 4.6096e+00, 4.6523e+00, 4.6954e+00,\n",
              "        4.7389e+00, 4.7828e+00, 4.8271e+00, 4.8718e+00, 4.9169e+00, 4.9624e+00,\n",
              "        5.0084e+00, 5.0548e+00, 5.1016e+00, 5.1489e+00, 5.1966e+00, 5.2447e+00,\n",
              "        5.2933e+00, 5.3423e+00, 5.3918e+00, 5.4417e+00, 5.4921e+00, 5.5430e+00,\n",
              "        5.5943e+00, 5.6461e+00, 5.6984e+00, 5.7512e+00, 5.8045e+00, 5.8582e+00,\n",
              "        5.9125e+00, 5.9673e+00, 6.0225e+00, 6.0783e+00, 6.1346e+00, 6.1914e+00,\n",
              "        6.2488e+00, 6.3067e+00, 6.3651e+00, 6.4240e+00, 6.4835e+00, 6.5436e+00,\n",
              "        6.6042e+00, 6.6654e+00, 6.7271e+00, 6.7894e+00, 6.8523e+00, 6.9158e+00,\n",
              "        6.9798e+00, 7.0445e+00, 7.1097e+00, 7.1756e+00, 7.2420e+00, 7.3091e+00,\n",
              "        7.3768e+00, 7.4451e+00, 7.5141e+00, 7.5837e+00, 7.6539e+00, 7.7248e+00,\n",
              "        7.7964e+00, 7.8686e+00, 7.9415e+00, 8.0150e+00, 8.0892e+00, 8.1642e+00,\n",
              "        8.2398e+00, 8.3161e+00, 8.3931e+00, 8.4709e+00, 8.5493e+00, 8.6285e+00,\n",
              "        8.7084e+00, 8.7891e+00, 8.8705e+00, 8.9527e+00, 9.0356e+00, 9.1193e+00,\n",
              "        9.2037e+00, 9.2890e+00, 9.3750e+00, 9.4618e+00, 9.5495e+00, 9.6379e+00,\n",
              "        9.7272e+00, 9.8173e+00, 9.9082e+00, 1.0000e+01])"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stepi = []\n",
        "lrei = []\n",
        "lossi = []\n",
        "\n",
        "for i in range(1000):\n",
        "  #forward pass\n",
        "  emb = C[X[:32]]\n",
        "  logits = ((emb.view(-1,6) @ W1 + b1).tanh()) @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Y[:32])\n",
        "\n",
        "  #backward\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr = lrs[i]\n",
        "  #tune the parameters\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  stepi.append(i)\n",
        "  lrei.append(lr)\n",
        "  lossi.append(loss.item())"
      ],
      "metadata": {
        "id": "jeq2uC6ukYAK"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lrei, lossi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "6QHvYE6Co7ii",
        "outputId": "9df3e15e-b4a8-4a84-8c93-ff5726338970"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcf13854fa0>]"
            ]
          },
          "metadata": {},
          "execution_count": 205
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So based on these we can see it's very stable when it's around -0.1. therefore it can be used as the learning rate"
      ],
      "metadata": {
        "id": "nnUaTK1PaisC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(stepi, lossi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Nwe_ndF-H_OU",
        "outputId": "28e8c58f-b852-47b7-c9af-45f1c6f1828d"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcf1366f5e0>]"
            ]
          },
          "metadata": {},
          "execution_count": 208
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X] \n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7B2LyOP7jRb",
        "outputId": "613ca7f9-c0ee-4677-c074-b9f8bd4453c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.8584, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
        "for i in range(C.shape[0]):\n",
        "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
        "plt.grid('minor')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "K2gqxyR1-WTV",
        "outputId": "f0cdf286-afa4-4894-adc7-3758ca04cf28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(20):\n",
        "    \n",
        "    out = []\n",
        "    context = [0] * block_size\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] \n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "    \n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEpVjXao-iEQ",
        "outputId": "f493cd5e-915e-47dc-ec12-44cd6f49d027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to.\n",
            "tokaoutle.\n",
            "tolmillilltlrelnebdstlilatmi.\n",
            "tolmilleusssdssslatmatlt.\n",
            "tosmatenrilate.\n",
            "toknile.\n",
            "to.\n",
            "to.\n",
            "to.\n",
            "toknutdlt.\n",
            "tommile.\n",
            "tomnutlatltltllatstssstli.\n",
            "tolmstnatepmate.\n",
            "to.\n",
            "emlutp.\n",
            "ttnatelaltolqllltlelastolmitelrnatstlittlatjatlt.\n",
            "ttnile.\n",
            "tolmute.\n",
            "to.\n",
            "tolmitratle.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyN6rB-B-oZe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxJUotWRs8tNgMRLZIdZg5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}